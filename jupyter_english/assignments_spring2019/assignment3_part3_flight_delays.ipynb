{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90e3a2685594cc6aae3914d3d519be153b050d78"
   },
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "</center> \n",
    "     \n",
    "## <center>  [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n",
    "\n",
    "#### <center> Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko) \n",
    "\n",
    "# <center>Assignment #3. Spring 2019\n",
    "## <center> Part 3. Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1cc3855272f09bf4b32a22bcf317d7ea22564706"
   },
   "source": [
    "**In this assignment, you're asked to beat a baseline in the [\"Flight delays\" competition](https://www.kaggle.com/c/flight-delays-fall-2018).**\n",
    "\n",
    "Prior to working on the assignment, you'd better check out the corresponding course material:\n",
    " 1. [Classification, Decision Trees and k Nearest Neighbors](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), the same as an interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn) \n",
    " 2. Ensembles:\n",
    "  - [Bagging](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part1_bagging.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging)\n",
    "  - [Random Forest](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part2_random_forest.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest)\n",
    "  - [Feature Importance](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part3_feature_importance.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-3-feature-importance)\n",
    " 3. - [Gradient boosting](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic10_boosting/topic10_gradient_boosting.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting) \n",
    "   - Logistic regression, Random Forest, and LightGBM in the \"Kaggle Forest Cover Type Prediction\" competition: [Kernel](https://www.kaggle.com/kashnitsky/topic-10-practice-with-logit-rf-and-lightgbm) \n",
    " 4. You can also practice with demo assignments, which are simpler and already shared with solutions:\n",
    "  - \"Decision trees with a toy task and the UCI Adult dataset\": [assignment](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees) + [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution)\n",
    "  - \"Logistic Regression and Random Forest in the credit scoring problem\": [assignment](https://www.kaggle.com/kashnitsky/assignment-5-logit-and-rf-for-credit-scoring) + [solution](https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring-sol)\n",
    " 5. There are also 7 video lectures on trees, forests, boosting and their applications: [mlcourse.ai/video](https://mlcourse.ai/video) \n",
    "\n",
    "### Your task is to:\n",
    " 1. beat **\"A3 baseline (8 credits)\"** on Public LB (**0.73449** LB score)\n",
    " 2. rename your [team](https://www.kaggle.com/c/flight-delays-fall-2018/team) in full accordance with the course rating\n",
    " \n",
    " This task is intended to be relatively easy. Here you are not required to upload your reproducible solution.\n",
    " \n",
    "### <center> Deadline for A3: 2019 March 31, 20:59 GMT (London time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b486c4beb6f64fbeb70610a0e5ed7145256605e1"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from the [competition page](https://www.kaggle.com/c/flight-delays-fall-2018/data) and change paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e7833f60e9392ba0526aec5b68ea8587ce90274"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('flight_delays_train.csv')\n",
    "test_df = pd.read_csv('flight_delays_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c02aa9ea53a2733cd5683bd10beed2b561acf7bb"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a0f1e18cc9b10cfd4f098183511f21722e61752"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce71f38fec3d94108609ef0cae861010ab0e8ca6"
   },
   "source": [
    "Given flight departure time, carrier's code, departure airport, destination location, and flight distance, you have to predict departure delay for more than 15 minutes. As the simplest benchmark, let's take logistic regression and two features that are easiest to take: DepTime and Distance. This will correspond to **\"simple logit baseline\"** on Public LB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bac98797b2bfb23851d735ec3761fc0e1401e61"
   },
   "outputs": [],
   "source": [
    "X_train = train_df[['Distance', 'DepTime']].values \n",
    "y_train = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\n",
    "X_test = test_df[['Distance', 'DepTime']].values\n",
    "\n",
    "X_train_part, X_valid, y_train_part, y_valid = \\\n",
    "    train_test_split(X_train, y_train, \n",
    "                     test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e99742ad807b66899de68241b60cf8310fb306c"
   },
   "outputs": [],
   "source": [
    "logit_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                       ('logit', LogisticRegression(C=1, random_state=17, solver='liblinear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "309be359915c00cbad41384a08926ddf25d47c7b"
   },
   "outputs": [],
   "source": [
    "logit_pipe.fit(X_train_part, y_train_part)\n",
    "logit_valid_pred = logit_pipe.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, logit_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "082bfede543f62192c55146294cdb23b3b898c90"
   },
   "outputs": [],
   "source": [
    "logit_pipe.fit(X_train, y_train)\n",
    "logit_test_pred = logit_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "pd.Series(logit_test_pred, \n",
    "          name='dep_delayed_15min').to_csv('logit_2feat.csv', \n",
    "                                           index_label='id', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "efd64f65bd3ac9d7fd279513a8cf49e7f2cb7ac0"
   },
   "source": [
    "Now you have to beat **\"A3 baseline (8 credits)\"** on Public LB. It's not challenging at all. Go for LightGBM, maybe some other models (or ensembling) as well. Include categorical features, do some simple feature engineering as well. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FREERIDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['dep_delayed_15min'] = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find out which one of Carriers top/anti-top in 15min_delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  train_df.groupby('dep_delayed_15min')['UniqueCarrier']\\\n",
    "        .value_counts()\\\n",
    "        .sort_index(level=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_by_target(df, target, feature, split_idx, level=0):\n",
    "    '''Group set by target and get feature distribution.\n",
    "    '''\n",
    "    # Group data by target.\n",
    "    grouped = df.groupby(target)[feature]\\\n",
    "        .value_counts()\\\n",
    "        .sort_index(level=level)\n",
    "\n",
    "    # Divide by target.\n",
    "    tmp_index = grouped.index.levels[1]\n",
    "    intime_term = grouped[:split_idx].values\n",
    "    delay_term = grouped[split_idx:].values\n",
    "\n",
    "    # Make a selection dataframe.\n",
    "    distr_df = pd.DataFrame([delay_term]).T\n",
    "    distr_df.set_index(tmp_index, inplace=True)\n",
    "    distr_df.columns = ['delay']\n",
    "    distr_df['intime'] = intime_term\n",
    "\n",
    "    distr_df['ratio'] = round(distr_df['delay'] / distr_df['intime'] * 100, 2)\n",
    "\n",
    "    return distr_df.sort_values(by='ratio', ascending=True)\n",
    "\n",
    "\n",
    "def plot_distribution(df, title):\n",
    "    '''Plot distributin of a feature by ratio.\n",
    "    '''\n",
    "    plt.figure(figsize=(11,6))\n",
    "    plt.barh(y=df.index, width=df.ratio)\n",
    "    plt.box(False)\n",
    "    plt.grid(False)\n",
    "    plt.title('Distribution of {}'.format(title))\n",
    "    plt.show();\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_carrier_distr = get_distribution_by_target(train_df, 'dep_delayed_15min', 'UniqueCarrier', 22, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_carrier_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(unique_carrier_distr, 'UniqueCarrier');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def make_dummy(df, feature: str, values: List[str]):\n",
    "    '''Make dummy feature matching extracted values from the list.\n",
    "    '''\n",
    "    return [1 if val in values else 0 for val in df[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_delay_carriers = unique_carrier_distr.index[-6:]\n",
    "top_intime_carriers = unique_carrier_distr.index[:2]\n",
    "\n",
    "top_delay_carriers, top_intime_carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['top_delay_carriers'] = make_dummy(train_df, 'UniqueCarrier', top_delay_carriers)\n",
    "test_df['top_delay_carriers'] = make_dummy(test_df, 'UniqueCarrier', top_delay_carriers)\n",
    "\n",
    "train_df['top_intime_carriers'] = make_dummy(train_df, 'UniqueCarrier', top_intime_carriers)\n",
    "test_df['top_intime_carriers'] = make_dummy(test_df, 'UniqueCarrier', top_intime_carriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of target by Month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change months` codes by numbers 1, 2, ..., 12 in train set.\n",
    "train_df.Month = train_df.Month.map(lambda name: np.float(name[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change months` codes by numbers 1, 2, ..., 12 in test set.\n",
    "test_df.Month = test_df.Month.map(lambda name: np.float(name[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_distr = get_distribution_by_target(train_df, 'dep_delayed_15min', 'Month', 12, level=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(month_distr, 'Month');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_delay_month = month_distr.index[-3:]\n",
    "top_intime_month = month_distr.index[:3]\n",
    "\n",
    "top_delay_month, top_intime_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['top_delay_month'] = make_dummy(train_df, 'Month', top_delay_month)\n",
    "test_df['top_delay_month'] = make_dummy(test_df, 'Month', top_delay_month)\n",
    "\n",
    "train_df['top_intime_month'] = make_dummy(train_df, 'Month', top_intime_month)\n",
    "test_df['top_intime_month'] = make_dummy(test_df, 'Month', top_intime_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day of Week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change day codes by numbers 1, 2, ..., 7 in train and test sets.\n",
    "train_df.DayOfWeek = train_df.DayOfWeek.map(lambda name: np.float(name[2:]))\n",
    "test_df.DayOfWeek = test_df.DayOfWeek.map(lambda name: np.float(name[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_distr = get_distribution_by_target(train_df, 'dep_delayed_15min', 'DayOfWeek', 7)\n",
    "day_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(day_distr, 'Day of the Week');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_delay_day = day_distr.index[-2:]\n",
    "top_intime_day = day_distr.index[:2]\n",
    "\n",
    "top_delay_day, top_intime_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['top_delay_day'] = make_dummy(train_df, 'DayOfWeek', top_delay_day)\n",
    "test_df['top_delay_day'] = make_dummy(test_df, 'DayOfWeek', top_delay_day)\n",
    "\n",
    "train_df['top_intime_day'] = make_dummy(train_df, 'DayOfWeek', top_intime_day)\n",
    "test_df['top_intime_day'] = make_dummy(test_df, 'DayOfWeek', top_intime_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert DepTime to hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['dep_hour'] = train_df.DepTime.map(lambda hour: float(hour // 100))\n",
    "test_df['dep_hour'] = test_df.DepTime.map(lambda hour: float(hour // 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df.dep_hour == 25, 'dep_hour'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_distr = get_distribution_by_target(train_df, 'dep_delayed_15min', 'dep_hour', 25)\n",
    "hour_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(hour_distr, 'Hour');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_delay_hour = hour_distr.index[-1:]\n",
    "top_delay_hour = hour_distr.index[-4:-1]\n",
    "most_intime_hour = hour_distr.index[:2]\n",
    "top_intime_hour = hour_distr.index[2:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['most_delay_hour', 'top_delay_hour', 'most_intime_hour', 'top_intime_hour']\n",
    "VALUES = most_delay_hour, top_delay_hour, most_intime_hour, top_intime_hour,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, values in zip(FEATURES, VALUES):\n",
    "    train_df[feature] = make_dummy(train_df, 'dep_hour', values)\n",
    "    test_df[feature] = make_dummy(test_df, 'dep_hour', values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dep_delayed_15min.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=train_df, x='Distance', hue='dep_delayed_15min', kind='swarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate Train and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([train_df.drop('dep_delayed_15min', axis=1), \n",
    "                     test_df])\n",
    "\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
